Automatically generated by Mendeley Desktop 1.13.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Browne2006,
abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other fields of inquiry), to compare Bayesian and likelihood-based methods for fitting variance-components (VC) and random-effects logistic regression (RELR) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood (ML) and restricted ML (REML) for Gaussian outcomes, and marginal and penalized quasi-likelihood (MQL and PQL) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo (MCMC) estimation, with adaptive hybrid Metropolis-Gibbs sampling for RELR models, and several diffuse prior distributions ($\Gamma$âˆ’1 ( , ) and U (0, 1 ) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level VC models we find that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which REML accomplishes this is an advantage, but (b) both approaches had difficulty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the three-level RELR models we examine we find that (c) quasi-likelihood methods for estimating random-effects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diffuse-prior methods lead to well-calibrated point and interval RELR estimates. While it is true that the likelihood-based methods we study are considerably faster computationally than MCMC, (i) steady improvements in recent years in both hardware speed and efficiency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods$\backslash$nin some common hierarchical settings combine to make MCMC-based Bayesian fitting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would benefit from further study of the type summarized here. $\backslash$n$\backslash$nKeywords: Adaptive MCMC, bias, calibration, diffuse priors, hierarchical modeling, hybrid Metropolis-Gibbs sampling, intraclass correlation, IGLS, interval coverage, MQL, mixed models, PQL, RIGLS, random-effects logistic regression, REML, variance-components models$\backslash$n},
author = {Browne, William J. and Draper, David},
doi = {10.1214/06-BA117},
file = {:Users/vissan1/Library/Mobile Documents/com\~{}apple\~{}CloudDocs/ucsc/ref/browne-draper-2006.pdf:pdf},
isbn = {1931-6690},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Adaptive MCMC,Bias,Calibration,Diffuse priors,Hierarchical modeling,Hybrid Metropolis-Gibbs sampling,IGLS,Interval coverage,Intraclass correlation,MQL,Mixed models,PQL,REML,RIGLS,Random-effects logistic regression,Variance-components models},
number = {3},
pages = {473--514},
title = {{A comparison of Bayesian and likelihood-based methods for fitting multilevel models}},
volume = {1},
year = {2006}
}
@misc{Hoos2004,
author = {Hoos, Holger H and St\"{u}tzle, Thomas},
file = {:Users/vissan1/Library/Mobile Documents/com\~{}apple\~{}CloudDocs/ucsc/ref/StochasticLocalSearch.pdf:pdf},
title = {{AAAI-04 Tutorial: Stochastic Local Search: Foundations and Applications}},
url = {http://www.stochastic-local-search.net/aaai-04-t-slides.pdf},
urldate = {26 Mar 2015},
year = {2004}
}
@article{Kirkpatrick1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
doi = {10.1126/science.220.4598.671},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
number = {4598},
pages = {671--680},
pmid = {17813860},
title = {{Optimization by simulated annealing.}},
volume = {220},
year = {1983}
}
