Automatically generated by Mendeley Desktop 1.14
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@online{AWS:EC2,
author = {{Amazon Web Services}},
title = {{Amazon Elastic Compute Cloud}},
url = {https://aws.amazon.com/ec2/}
}
@article{Dorigo2006,
abstract = {Swarm intelligence is a relatively new approach to problem solving that takes inspiration from the social behaviors of insects and of other animals. In particular, ants have inspired a number of methods and techniques among which the most studied and the most successful is the general purpose optimization technique known as ant colony optimization. Ant colony optimization (ACO) takes inspiration from the foraging behavior of some ant species. These ants deposit pheromone on the ground in order to mark some favorable path that should be followed by other members of the colony. Ant colony optimization exploits a similar mechanism for solving optimization problems. From the early nineties, when the first ant colony optimization algorithm was proposed, ACO attracted the attention of increasing numbers of researchers and many successful applications are now available. Moreover, a substantial corpus of theoretical results is becoming available that provides useful guidelines to researchers and practitioners in further applications of ACO. The goal of this article is to introduce ant colony optimization and to survey its most notable applications},
author = {Dorigo, Marco and Birattari, Mauro and Stutzle, Thomas},
journal = {Computational Intelligence Magazine, IEEE},
keywords = {Animals,Ant colony optimization,Bridges,Competitive intelligence,Computational and artificial intelligence,Computational intelligence,Fluctuations,Guidelines,Insects,Problem-solving,ant colony optimization,ant species,artificial ants,artificial life,computational intelligence,foraging behavior,insect social behaviors,particle swarm optimisation,swarm intelligence},
number = {4},
pages = {28--39},
title = {{Ant colony optimization}},
volume = {1},
year = {2006}
}
@book{BernadoSmith,
author = {Bernardo, Jos\'{e} M. and Smith, Adrian F. M.},
isbn = {047149464X},
publisher = {Wiley},
title = {{Bayesian Theory}},
year = {2000}
}
@article{Kirkpatrick1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
journal = {Science (New York, N.Y.)},
number = {4598},
pages = {671--680},
title = {{Optimization by simulated annealing.}},
volume = {220},
year = {1983}
}
@article{Glover1990,
abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
author = {Glover, F.},
journal = {INFORMS Journal on Computing},
number = {1},
pages = {4--32},
title = {{Tabu Search - Part II}},
volume = {2},
year = {1990}
}
@article{Glover1989,
abstract = {This paper presents the fundamental principles underlying tabu search as a strategy for combinatorial optimization problems. Tabu search has achieved impressive practical successes in applications ranging from scheduling and computer channel balancing to cluster analysis and space planning, and more recently has demonstrated its value in treating classical problems such as the traveling salesman and graph coloring problems. Nevertheless, the approach is still in its infancy, and a good deal remains to be discovered about its most effective forms of implementation and about the range of problems for which it is best suited. This paper undertakes to present the major ideas and findings to date, and to indicate challenges for future research. Part I of this study indicates the basic principles, ranging from the short-term memory process at the core of the search to the intermediate and long term memory processes for intensifying and diversifying the search. Included are illustrative data structures for implementing the tabu conditions (and associated aspiration criteria) that underlie these processes. Part I concludes with a discussion of probabilistic tabu search and a summary of computational experience for a variety of applications. Part II of this study (to appear in a subsequent issue) examines more advanced considerations, applying the basic ideas to special settings and outlining a dynamic move structure to insure finiteness. Part II also describes tabu search methods for solving mixed integer programming problems and gives a brief summary of additional practical experience, including the use of tabu search to guide other types of processes, such as those of neural networks.},
author = {Glover, F},
journal = {ORSA Journal on Computing},
keywords = {Combinatorial Problems,Integer Programming,TS,Tabu Search},
number = {3},
pages = {190--206},
title = {{Tabu Search - Part I}},
volume = {1},
year = {1989}
}
@book{Holland1992,
address = {Cambridge, MA},
author = {Holland, J.H.},
edition = {2nd edition},
publisher = {MIT Press},
title = {{Adaptation in Natural and Artificial Systems}},
year = {1992}
}
@book{Hoos2004,
address = {San Francisco, CA, USA},
author = {Hoos, Holger and Stutzle, Thomas},
isbn = {1558608729},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Stochastic Local Search: Foundations and Applications}},
url = {http://dl.acm.org/citation.cfm?id=983505},
year = {2004}
}
@online{Interoute:WhatIsCloudComputing,
author = {Interoute},
publisher = {Interoute Communications},
title = {{What is Cloud Computing?}},
url = {http://www.interoute.com/cloud-article/what-cloud-computing},
year = {2015}
}
@book{Pinedo2012,
abstract = {This new edition of the well established text Scheduling - Theory, Algorithms, and Systems provides an up-to-date coverage of important theoretical models in the scheduling literature as well as significant scheduling problems that occur in the real world. It again includes supplementary material in the form of slide-shows from industry and movies that show implementations of scheduling systems. The main structure of the book as per previous edition consists of three parts. The first part focuses on deterministic scheduling and the related combinatorial problems. The second part covers probabilistic scheduling models; in this part it is assumed that processing times and other problem data are random and not known in advance. The third part deals with scheduling in practice; it covers heuristics that are popular with practitioners and discusses system design and implementation issues. All three parts of this new edition have been revamped and streamlined. The references have been made completely up-to-date. Theoreticians and practitioners alike will find this book of interest. Graduate students in operations management, operations research, industrial engineering, and computer science will find the book an accessible and invaluable resource. Scheduling - Theory, Algorithms, and Systems will serve as an essential reference for professionals working on scheduling problems in manufacturing, services, and other environments. Michael L. Pinedo is the Julius Schlesinger Professor of Operations Management in the Stern School of Business at New York University. Reviews of third edition: This well-established text covers both the theory and practice of scheduling. he book begins with motivating examples and the penultimate chapter Reviews of third edition: This well-established text covers both the theory and practice of scheduling. The book begins with motivating examples and the penultimate chapter discusses some commercial scheduling systems and examples of their implementations." (Mathematical Reviews, 2009)},
author = {Pinedo, Michael L.},
booktitle = {Scheduling: Theory, Algorithms, and Systems},
edition = {4th ed.},
isbn = {1461419867},
pages = {1--676},
publisher = {Springer},
title = {{Scheduling: Theory, algorithms, and systems}},
year = {2012}
}
@online{mathworld:bellnumber,
annote = {Last visited on 6/5/2015},
author = {Weisstein, Eric W},
title = {{Bell Number. \{From MathWorld---A Wolfram Web Resource\}}},
url = {http://mathworld.wolfram.com/BellNumber.html},
year = {2015}
}
@book{Efron1993,
abstract = {Statistics is a subject of many uses and surprisingly few effective practitioners. The traditional road to statistical knowledge is blocked, for most, by a formidable wall of mathematics. The approach in An Introduction to the Bootstrap avoids that wall. It arms scientists and engineers, as well as statisticians, with the computational techniques they need to analyze and understand complicated data sets.},
author = {Efron, B and Tibshirani, R J},
booktitle = {Chapman \& Hall/CRC Monographs on Statistics \& Applied Probability},
edition = {1st edition},
isbn = {0412042312},
pages = {456},
publisher = {Chapman and Hall/CRC},
title = {{An Introduction to the Bootstrap}},
year = {1993}
}
@article{Glass1994,
author = {Glass, C A and Potts, C N and Shade, P},
journal = {Mathematical and Computer Modelling},
number = {2},
pages = {41--52},
publisher = {Elsevier Science Ltd.},
title = {{Unrelated parallel machine scheduling using local search}},
volume = {20},
year = {1994}
}
@thesis{Fouskakis2001,
author = {Fouskakis, Dimitris},
institution = {University of Bath, UK},
title = {{Stochastic Optimization Methods for Cost-Effect Quality Assessment in Health}},
type = {Ph.D. Thesis},
year = {2001}
}
@article{Browne2006,
abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other fields of inquiry), to compare Bayesian and likelihood-based methods for fitting variance-components (VC) and random-effects logistic regression (RELR) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood (ML) and restricted ML (REML) for Gaussian outcomes, and marginal and penalized quasi-likelihood (MQL and PQL) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo (MCMC) estimation, with adaptive hybrid Metropolis-Gibbs sampling for RELR models, and several diffuse prior distributions ($\Gamma$âˆ’1 ( , ) and U (0, 1 ) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level VC models we find that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which REML accomplishes this is an advantage, but (b) both approaches had difficulty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the three-level RELR models we examine we find that (c) quasi-likelihood methods for estimating random-effects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diffuse-prior methods lead to well-calibrated point and interval RELR estimates. While it is true that the likelihood-based methods we study are considerably faster computationally than MCMC, (i) steady improvements in recent years in both hardware speed and efficiency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods$\backslash$nin some common hierarchical settings combine to make MCMC-based Bayesian fitting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would benefit from further study of the type summarized here. $\backslash$n$\backslash$nKeywords: Adaptive MCMC, bias, calibration, diffuse priors, hierarchical modeling, hybrid Metropolis-Gibbs sampling, intraclass correlation, IGLS, interval coverage, MQL, mixed models, PQL, RIGLS, random-effects logistic regression, REML, variance-components models$\backslash$n},
author = {Browne, William J. and Draper, David},
doi = {10.1214/06-BA117},
file = {:Users/vissan1/Library/Mobile Documents/com\~{}apple\~{}CloudDocs/ucsc/ref/browne-draper-2006.pdf:pdf},
isbn = {1931-6690},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Adaptive MCMC,Bias,Calibration,Diffuse priors,Hierarchical modeling,Hybrid Metropolis-Gibbs sampling,IGLS,Interval coverage,Intraclass correlation,MQL,Mixed models,PQL,REML,RIGLS,Random-effects logistic regression,Variance-components models},
number = {3},
pages = {473--514},
title = {{A comparison of Bayesian and likelihood-based methods for fitting multilevel models}},
volume = {1},
year = {2006}
}
@online{RightScale:2015,
author = {RightScale},
publisher = {RightScale, Inc.},
title = {{State of the Cloud Report}},
url = {http://www.rightscale.com},
year = {2015}
}
@article{Garey1979,
abstract = {This book's introduction features a humorous story of a man with a line of people behind him, who explains to his boss, "I can't find an efficient algorithm, but neither can all these famous people." This man illustrates an important quality of a class of problems, namely, the NP-complete problems: if you can prove that a problem is in this class, then it has no known polynomial-time solution that is guaranteed to work in general. This quality implies that the problem is difficult to deal with in practice. The focus of this book is to teach the reader how to identify, deal with, and understand the essence of NP-complete problems; Computers and Intractability does all of those things effectively. In a readable yet mathematically rigorous manner, the book covers topics such as how to prove that a given problem is NP-complete and how to cope with NP-complete problems. (There is even a chapter on advanced topics, with numerous references.) Computers and Intractability also contains a list of more than 300 problems-most of which are known to be NP-complete-with comments and references.},
author = {Garey, M R and Johnson, D S},
file = {:Users/vissan1/Library/Application Support/Mendeley Desktop/Downloaded/Garey, Johnson - 1979 - Computers and Intractability A Guide to the Theory of NP-Completeness (Series of Books in the Mathematical Scien.pdf:pdf},
isbn = {0716710455},
journal = {Computers and Intractability},
pages = {340},
title = {{Computers and Intractability: A Guide to the Theory of NP-Completeness (Series of Books in the Mathematical Sciences)}},
year = {1979}
}
@online{AWS:Spot,
author = {{Amazon Web Services}},
title = {{Amazon EC2 Spot Instances}},
url = {http://aws.amazon.com/ec2/purchasing-options/spot-instances/}
}
