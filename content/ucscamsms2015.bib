Automatically generated by Mendeley Desktop 1.13.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Dorigo2006,
abstract = {Swarm intelligence is a relatively new approach to problem solving that takes inspiration from the social behaviors of insects and of other animals. In particular, ants have inspired a number of methods and techniques among which the most studied and the most successful is the general purpose optimization technique known as ant colony optimization. Ant colony optimization (ACO) takes inspiration from the foraging behavior of some ant species. These ants deposit pheromone on the ground in order to mark some favorable path that should be followed by other members of the colony. Ant colony optimization exploits a similar mechanism for solving optimization problems. From the early nineties, when the first ant colony optimization algorithm was proposed, ACO attracted the attention of increasing numbers of researchers and many successful applications are now available. Moreover, a substantial corpus of theoretical results is becoming available that provides useful guidelines to researchers and practitioners in further applications of ACO. The goal of this article is to introduce ant colony optimization and to survey its most notable applications},
author = {Dorigo, Marco and Birattari, Mauro and Stutzle, Thomas},
doi = {10.1109/MCI.2006.329691},
isbn = {0262042193},
issn = {1556-603X},
journal = {Computational Intelligence Magazine, IEEE},
keywords = {Animals,Ant colony optimization,Bridges,Competitive intelligence,Computational and artificial intelligence,Computational intelligence,Fluctuations,Guidelines,Insects,Problem-solving,ant colony optimization,ant species,artificial ants,artificial life,computational intelligence,foraging behavior,insect social behaviors,particle swarm optimisation,swarm intelligence},
number = {4},
pages = {28--39},
pmid = {22074763},
title = {{Ant colony optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4129846},
volume = {1},
year = {2006}
}
@misc{Hoos2004,
author = {Hoos, Holger H and St\"{u}tzle, Thomas},
file = {:Users/vissan1/Library/Mobile Documents/com\~{}apple\~{}CloudDocs/ucsc/ref/StochasticLocalSearch.pdf:pdf},
title = {{AAAI-04 Tutorial: Stochastic Local Search - Foundations and Applications}},
url = {http://www.stochastic-local-search.net/aaai-04-t-slides.pdf},
urldate = {2015-03-26},
year = {2004}
}
@article{Kirkpatrick1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
doi = {10.1126/science.220.4598.671},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
number = {4598},
pages = {671--680},
pmid = {17813860},
title = {{Optimization by simulated annealing.}},
volume = {220},
year = {1983}
}
@article{Browne2006,
abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other fields of inquiry), to compare Bayesian and likelihood-based methods for fitting variance-components (VC) and random-effects logistic regression (RELR) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood (ML) and restricted ML (REML) for Gaussian outcomes, and marginal and penalized quasi-likelihood (MQL and PQL) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo (MCMC) estimation, with adaptive hybrid Metropolis-Gibbs sampling for RELR models, and several diffuse prior distributions ($\Gamma$âˆ’1 ( , ) and U (0, 1 ) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level VC models we find that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which REML accomplishes this is an advantage, but (b) both approaches had difficulty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the three-level RELR models we examine we find that (c) quasi-likelihood methods for estimating random-effects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diffuse-prior methods lead to well-calibrated point and interval RELR estimates. While it is true that the likelihood-based methods we study are considerably faster computationally than MCMC, (i) steady improvements in recent years in both hardware speed and efficiency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods$\backslash$nin some common hierarchical settings combine to make MCMC-based Bayesian fitting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would benefit from further study of the type summarized here. $\backslash$n$\backslash$nKeywords: Adaptive MCMC, bias, calibration, diffuse priors, hierarchical modeling, hybrid Metropolis-Gibbs sampling, intraclass correlation, IGLS, interval coverage, MQL, mixed models, PQL, RIGLS, random-effects logistic regression, REML, variance-components models$\backslash$n},
author = {Browne, William J. and Draper, David},
doi = {10.1214/06-BA117},
file = {:Users/vissan1/Library/Mobile Documents/com\~{}apple\~{}CloudDocs/ucsc/ref/browne-draper-2006.pdf:pdf},
isbn = {1931-6690},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Adaptive MCMC,Bias,Calibration,Diffuse priors,Hierarchical modeling,Hybrid Metropolis-Gibbs sampling,IGLS,Interval coverage,Intraclass correlation,MQL,Mixed models,PQL,REML,RIGLS,Random-effects logistic regression,Variance-components models},
number = {3},
pages = {473--514},
title = {{A comparison of Bayesian and likelihood-based methods for fitting multilevel models}},
volume = {1},
year = {2006}
}
@article{Glover1989,
abstract = {This paper presents the fundamental principles underlying tabu search as a strategy for combinatorial optimization problems. Tabu search has achieved impressive practical successes in applications ranging from scheduling and computer channel balancing to cluster analysis and space planning, and more recently has demonstrated its value in treating classical problems such as the traveling salesman and graph coloring problems. Nevertheless, the approach is still in its infancy, and a good deal remains to be discovered about its most effective forms of implementation and about the range of problems for which it is best suited. This paper undertakes to present the major ideas and findings to date, and to indicate challenges for future research. Part I of this study indicates the basic principles, ranging from the short-term memory process at the core of the search to the intermediate and long term memory processes for intensifying and diversifying the search. Included are illustrative data structures for implementing the tabu conditions (and associated aspiration criteria) that underlie these processes. Part I concludes with a discussion of probabilistic tabu search and a summary of computational experience for a variety of applications. Part II of this study (to appear in a subsequent issue) examines more advanced considerations, applying the basic ideas to special settings and outlining a dynamic move structure to insure finiteness. Part II also describes tabu search methods for solving mixed integer programming problems and gives a brief summary of additional practical experience, including the use of tabu search to guide other types of processes, such as those of neural networks.},
author = {Glover, F},
doi = {10.1287/ijoc.1.3.190},
isbn = {079239965X},
issn = {0899-1499},
journal = {ORSA Journal on Computing},
keywords = {Combinatorial Problems,Integer Programming,TS,Tabu Search},
number = {3},
pages = {190--206},
pmid = {2758},
title = {{Tabu Search - Part I}},
url = {http://leeds-faculty.colorado.edu/glover/TS\{\%\}20-\{\%\}20Part\{\%\}20I-ORSA.pdf},
volume = {1},
year = {1989}
}
@article{Glover1990,
abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
author = {Glover, F.},
doi = {10.1287/ijoc.2.1.4},
isbn = {1091-9856},
issn = {1091-9856},
journal = {INFORMS Journal on Computing},
number = {1},
pages = {4--32},
title = {{Tabu Search--Part II}},
volume = {2},
year = {1990}
}
@book{Holland1992,
address = {Cambridge, MA},
author = {Holland, J.H.},
edition = {2nd editio},
publisher = {MIT Press},
title = {{Adaptation in Natural and Artificial Systems}},
year = {1992}
}
