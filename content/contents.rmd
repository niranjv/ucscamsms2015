---
bibliography: ucscamsms2015.bib
---

```{r cache=FALSE, echo=FALSE}
  knitr::read_chunk('../bin/plot.R')
```

```{r init, echo=FALSE}
```

# Introduction

This is the introduction

Testing nomenclature:

$a=\frac{N}{A}$
\nomenclature{$a$}{The number of angels per unit area}
\nomenclature{$N$}{The number of angels per needle point}
\nomenclature{$A$}{The area of the needle point}

The equation $\sigma = m a$
\nomenclature{$\sigma$}{The total mass of angels per unit area}
\nomenclature{$m$}{The mass of one angel}
follows easily.

This is a reference to [@a778431]


# Scoring an Assignment

**Overview**:

* Aim: Assign a numerical value (score) to each candidate solution.
* Use maxi-min criterion

* Utility = Benefit (\$) - Runtime (hrs) x MachineCost (\$/hr)
* Benefit and MachineCost are fixed
* Need an upper bound for job runtime s.t. job will complete by this bound with
95% probability;
* The actual job runtime (sum of runtimes of tasks in job) must be below this
upper bound 95 times out of 100 (this is calibration)
* To get dist. of job runtime:
 * \< 50 tasks/job: use bootstrap sampling of training set samples
 * \>= 50 tasks/job: use Normal approx. (via CLT)
* Do this for all machines in the action space and pick the machine with the
highest utility


## Case 1: < 50 tasks/job
* Runtime dist. generated via bootstrap sampling
* Shape of dist. depends on number of bootstrap samples


Figure \ref{fig:bootstrap-95pct-ub-1processor-1task} shows the 95% upper bound
on runtimes for jobs with 1 task (and processed on a single processor). Figures
\ref{fig:bootstrap-95pct-ub-1processor-10tasks} and
\ref{fig:bootstrap-95pct-ub-1processor-50tasks} show similar bounds for jobs
with 10 and 50 tasks respectively.

``` {r bootstrap-95pct-ub-1processor-1task, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 1 task (runtime distribution generated by bootstrap re-sampling) \\label{fig:bootstrap-95pct-ub-1processor-1task}'}
```

``` {r bootstrap-95pct-ub-1processor-10tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 10 tasks (runtime distribution generated by bootstrap re-sampling \\label{fig:bootstrap-95pct-ub-1processor-10tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-50tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 50 tasks (runtime distribution generated by bootstrap re-sampling \\label{fig:bootstrap-95pct-ub-1processor-50tasks}'}
```

Example of scheduling 3 tasks on 1 instance. The time series of scores for this
example is shown in Figure \ref{fig:sched-3task-2inst}.

``` {r sched-3task-2inst, echo=FALSE, fig.cap='Caption: Schedule 3 tasks on 1 instance \\label{fig:sched-3task-2inst}'}
```

Example of scheduling 1 task on 1 instance. The relevant figure is Figure
\ref{fig:sched-1task-1inst}.

``` {r sched-1task-1inst, echo=FALSE, fig.cap='Caption: Schedule 1 task on 1 instance \\label{fig:sched-1task-1inst}'}
```

## Case 2: > 50 tasks/job
* Runtime dist. generated via Normal approx. (CLT)

Figures \ref{fig:bootstrap-95pct-ub-1processor-100tasks} and
\ref{fig:bootstrap-95pct-ub-1processor-150tasks} shows the 95% upper bound on
runtimes for jobs with 100 tasks (and processed on a single processor).The upper
bound is generated via a Normal approximation to the distribution of job
runtimes (via CLT).

``` {r bootstrap-95pct-ub-1processor-100tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 100 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-100tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-150tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 150 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-150tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-200tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 200 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-200tasks}'}
```


# Finding the optimal assignment

This section is about finding the optimal assignment.

For each cluster + instance type combination:
* Step 1 (optimization): find an 'optimal' assignment under the given
constraints that completes the job at the earliest possible time
* Step 2 (decision): decide if the assignment meets the deadline constraint
(i.e., assignment will allow job to complete by deadline with 95% prob.)

Final decision: choose the assignment with the best score from those
assignments that satisfy the deadline constraints


## Case 1: < 50 tasks/job

## Case 2: > 50 tasks/job

*Validation*

* When runtimes are exponentially distributed, compare with LEPTF
* When runtimes are NOT exponentially distributed, compare with 'truth'
generated by exhaustive search of sample space


# Conclusions and future work

## Conclusions

This is the conclusion

## Future work

The methodology developed above can be extended by the following ways:

### Alternative stochastic local search methods
The simulated annealing algorithm [@Kirkpatrick1983] used in Chapter 3 for finding the optimal assignment is just one member of a class of algorithms known as meta-heuristics for solving combinatorial problems.
Other members of this class include tabu search [@Glover1989], [@Glover1990], genetic algorithms [@Holland1992], Ant Colony Optimization [@Dorigo2006] and their variants [@Hoos2004].
For tabu search, this can be done by ...
For genetic algorithmd, this can be done by ...
For ant colony optimization, this can be done by ...


### Improved candidate generation
The efficiency of the SA algorithm is strongly influenced by the methods used to generate candidate assignments.
Candidate assignments are currently generated by moving or exchanging a random number of randomly chosen tasks between 2 randomly chosen processors in the cluster.
Upto one-third of the tasks assigned to a processor can be moved or exchanged with another processor (the one-third limit is entirely arbitrary).
This can sometimes result in 'lopsided' assignments where some processors are assigned no tasks or very few tasks while other processors are assigned most of the tasks in the job.
If the number of tasks in the job is large and the deadline is tight, such assignments are very unlikely to complete the job by the deadline.
Since computing the score for an assignment is the most time consuming step in the algorithm, such assignments should be rejected before the score computation step.
This pruning will result in a speedup proportional to the number of 'lopsided' assignments that are generated.
An initial definition of a 'lopsided' assignment could be one thats contains a processor that is assigned very few tasks, e.g. less than half the average number of tasks/processor in the best assignment found so far.

The number of tasks shifted between 2 processors is currently independent of the temperature and can vary from 1 to one-third the number of tasks assigned to a processor.
This means that it is possible to generate candidate assignments that are very different from the current best assignment even when the temperature is very low.
Since the number of assignments with low scores is greater than the number of assignments with high scores, the candidate generation process might be improved by decreasing the number of the tasks shifted as the temperature decreases.


### Low temperature starts
Start with a 'good' solution and low temperature so we don't waste time exploring assignments that are worse than the initial assignment.

### Re-initialize cooling schedule
Re-initialize cooling schedule around best known solution

### Alternative cooling schedules
e.g., geometric cooling schedule where
$T_{n+1} = \alpha * T_{n}$, where $0 < \alpha < 1$, $n=0,1,2,...$

### Extension to Spot instances
Currently, cost = runtime (hrs) x cost (\$/hr).
Cost is assumed to be fixed while runtime is variable.
Spot instances are much cheaper by their cost is variable.
This introduced additional level of uncertainty into the model.
Cost for Spot instances is given as time series data generated from an unknown model.
Need to model the cost effectively and pick a maximum bid price such that the job is not interrupted because the current Spot price exceeds the max bid price.
Can extend this further by using a low bid price with checkpointing and re-processing the task that was interrupted and processing all remaining tasks
Need to consider the possibility that might not get a Spot instance and will have to use an On Demand instance instead for the remaining tasks.

### Variance of runtimes & training set sample sizes
Currently using a fixed number of samples for each task size.
It is possible that different task sizes will have different number of training set samples.
Runtimes for task sizes with large number of training set samples will have lower variance that runtimes for sizes with fewer number of samples.
Also, the same task size can have different number of samples for different instances types.
Similarly, runtimes for a size on an instance with a large number of samples will have lower variance than runtimes for the same size on other instances with fewer number of samples.
Can choose to run task on instance type with fewer number of samples in case it turns out to faster than an instance type with more samples.
Possible use of multi-armed bandits to balance explore vs. exploit here since runtimes for current set of tasks will be added to training set for tasks from the next job.

### Skip runtime estimation for small cluster sizes
The runtime for the current scoring algorithm increases as the square of the number of the number of instances in the cluster.
When trying to determine the minimum number of instances in a cluster of a certain instance type that will complete the job by the deadline, we should ignore clusters with too few instances and focus only on cluster sizes that have a reasonable chance of completing the job by the deadline.
Use the min values in the training set for each size and see if the cluster is able to complete them by the deadline.
If not, move on to the next size.


### Move bootstrap code from R to C++
All code in the `schedulr` R package is in R.
This means that

All code is currently in R and can take several minutes to run depending on the number of instances and tasks.
Move the bootstrap code to C++ and call from R via RCpp to improve runtimes.



# Bibliography
