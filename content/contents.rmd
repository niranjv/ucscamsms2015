---
bibliography: biblio.bib
---

```{r cache=FALSE, echo=FALSE}
  knitr::read_chunk('../bin/plot.R')
```

```{r init, echo=FALSE}
```

# Introduction

This is the introduction

Testing nomenclature:

$a=\frac{N}{A}$
\nomenclature{$a$}{The number of angels per unit area}
\nomenclature{$N$}{The number of angels per needle point}
\nomenclature{$A$}{The area of the needle point}

The equation $\sigma = m a$
\nomenclature{$\sigma$}{The total mass of angels per unit area}
\nomenclature{$m$}{The mass of one angel}
follows easily.

This is a reference to [@a778431]


# Single Processor case

**Overview**:

* Utility = Benefit (\$) - Runtime (hrs) x MachineCost (\$/hr)
* Benefit and MachineCost are fixed
* Need an upper bound for job runtime s.t. job will complete by this bound with
95% probability;
* The actual job runtime (sum of runtimes of tasks in job) must be below this
upper bound 95 times out of 100 (this is calibration)
* To get dist. of job runtime:
 * \< 50 tasks/job: use bootstrap sampling of training set samples
 * \>= 50 tasks/job: use Normal approx. (via CLT)
* Do this for all machines in the action space and pick the machine with the
highest utility


## Case 1: < 50 tasks/job
* Runtime dist. generated via bootstrap sampling
* Shape of dist. depends on number of bootstrap samples


Figure \ref{fig:bootstrap-95pct-ub-1processor-1task} shows the 95% upper bound
on runtimes for jobs with 1 task (and processed on a single processor). Figures
\ref{fig:bootstrap-95pct-ub-1processor-10tasks} and
\ref{fig:bootstrap-95pct-ub-1processor-50tasks} show similar bounds for jobs
with 10 and 50 tasks respectively.

``` {r bootstrap-95pct-ub-1processor-1task, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 1 task (runtime distribution generated by bootstrap re-sampling) \\label{fig:bootstrap-95pct-ub-1processor-1task}'}
```

``` {r bootstrap-95pct-ub-1processor-10tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 10 tasks (runtime distribution generated by bootstrap re-sampling \\label{fig:bootstrap-95pct-ub-1processor-10tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-50tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 50 tasks (runtime distribution generated by bootstrap re-sampling \\label{fig:bootstrap-95pct-ub-1processor-50tasks}'}
```

Example of scheduling 3 tasks on 1 instance. The time series of scores for this
example is shown in Figure \ref{fig:sched-3task-2inst}.

``` {r sched-3task-2inst, echo=FALSE, fig.cap='Caption: Schedule 3 tasks on 1 instance \\label{fig:sched-3task-2inst}'}
```

Example of scheduling 1 task on 1 instance. The relevant figure is Figure
\ref{fig:sched-1task-1inst}.

``` {r sched-1task-1inst, echo=FALSE, fig.cap='Caption: Schedule 1 task on 1 instance \\label{fig:sched-1task-1inst}'}
```

## Case 2: > 50 tasks/job
* Runtime dist. generated via Normal approx. (CLT)

Figures \ref{fig:bootstrap-95pct-ub-1processor-100tasks} and
\ref{fig:bootstrap-95pct-ub-1processor-150tasks} shows the 95% upper bound on
runtimes for jobs with 100 tasks (and processed on a single processor).The upper
bound is generated via a Normal approximation to the distribution of job
runtimes (via CLT).

``` {r bootstrap-95pct-ub-1processor-100tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 100 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-100tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-150tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 150 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-150tasks}'}
```

``` {r bootstrap-95pct-ub-1processor-200tasks, echo=FALSE, message=FALSE, fig.cap='95% upper bound on runtimes for jobs with 200 tasks (runtime distribution generated by Normal approximation via CLT \\label{fig:bootstrap-95pct-ub-1processor-200tasks}'}
```


# Multiple Processor case

## Case 1: < 50 tasks/job

## Case 2: > 50 tasks/job

*Validation*

* When runtimes are exponentially distributed, compare with LEPTF
* When runtimes are NOT exponentially distributed, compare with 'truth'
generated by exhaustive search of sample space


# Conclusions and future work

## Conclusions

This is the conclusion

## Future work

Future work includes extending the methodology developed above in the following ways:

### Extension to Spot instances
Currently, cost = runtime (hrs) x cost (\$/hr).
Cost is assumed to be fixed while runtime is variable.
Spot instances are much cheaper by their cost is variable.
This introduced additional level of uncertainty into the model.
Cost for Spot instances is given as time series data generated from an unknown model.
Need to model the cost effectively and pick a maximum bid price such that the job is not interrupted because the current Spot price exceeds the max bid price.
Can extend this further by using a low bid price with checkpointing and re-processing the task that was interrupted and processing all remaining tasks
Need to consider the possibility that might not get a Spot instance and will have to use an On Demand instance instead for the remaining tasks.

### Variance of runtimes & training set sample sizes
Currently using a fixed number of samples for each task size.
It is possible that different task sizes will have different number of training set samples.
Runtimes for task sizes with large number of training set samples will have lower variance that runtimes for sizes with fewer number of samples.
Also, the same task size can have different number of samples for different instances types.
Similarly, runtimes for a size on an instance with a large number of samples will have lower variance than runtimes for the same size on other instances with fewer number of samples.
Can choose to run task on instance type with fewer number of samples in case it turns out to faster than an instance type with more samples.
Possible use of multi-armed bandits to balance explore vs. exploit here since runtimes for current set of tasks will be added to training set for tasks from the next job.

### Move bootstrap code from R to C++
All code is currently in R and can take several minutes to run depending on the number of instances and tasks.
Move the bootstrap code to C++ and call from R via RCpp to improve runtimes.

### Skip runtime estimation for small cluster sizes
When trying to determine the minimum number of instances in a cluster of a certain instance type that will complete the job by the deadline, we should ignore clusters with too few instances and focus only on cluster sizes that have a reasonable chance of completing the job by the deadline.
Use the min values in the training set for each size and see if the cluster is able to complete them by the deadline.
If not, move on to the next size.


# Bibliography
