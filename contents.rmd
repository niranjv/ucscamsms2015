---
layout: default
title: default
bibliography: biblio.bib
---

# Introduction

This is the introduction

## Section 1

This is intro - section 1

## Section 2

This is intro - section 2

This is a reference to [@a778431]


# Single Processor case

## Case 1: < 50 tasks/job
* Runtime dist. generated via bootstrap sampling
* Shape of dist. depends on number of bootstrap samples

```{r init}
library(schedulr)

data(m3xlarge.runtimes.expdist)
setup.trainingset.runtimes('m3xlarge', m3xlarge.runtimes.expdist)

```

Example of scheduling 1 task on 1 instance. The relevant figure is Figure
\ref{fig:plot1}.

``` {r plot1, fig.cap='Caption: Schedule 1 task on 1 instance \\label{fig:plot1}'}

job <- c(1)
deadline <- 300
cluster.instance.type <- 'm3xlarge'
cluster.size <- 1
max.iter <- 10
max.temp <- 0.5
reset.score.pct <- 10

best.schedule <- schedule(job, deadline, cluster.instance.type, cluster.size,
max.iter, max.temp, reset.score.pct, debug=TRUE)
scores.ts <- attr(best.schedule, 'scores.ts')

imgTitle <- 'Probability of completing job by deadline'
plot(scores.ts[,1], scores.ts[,2], type='l', ylim=c(0,1), xlab='Iteration',
ylab='Score', main=imgTitle)
lines(scores.ts[,1], scores.ts[,5], type='l', col='#e41a1c')
grid()

```

Example of scheduling 3 tasks on 1 instance. The time series of scores for this
example is shown in Figure \ref{fig:plot2}.

``` {r plot2, fig.cap='Caption: Schedule 3 tasks on 1 instance \\label{fig:plot2}'}

job <- c(1,60,100)
deadline <- 300
cluster.instance.type <- 'm3xlarge'
cluster.size <- 1
max.iter <- 10
max.temp <- 0.5
reset.score.pct <- 10

best.schedule <- schedule(job, deadline, cluster.instance.type, cluster.size,
max.iter, max.temp, reset.score.pct, debug=TRUE)
scores.ts <- attr(best.schedule, 'scores.ts')

imgTitle <- 'Probability of completing job by deadline'
plot(scores.ts[,1], scores.ts[,2], type='l', ylim=c(0,1), xlab='Iteration',
ylab='Score', main=imgTitle)
lines(scores.ts[,1], scores.ts[,5], type='l', col='#e41a1c')
grid()

```


## Case 2: > 50 tasks/job
* Runtime dist. generated via Normal approx. (CLT)

### Validation
* 95% CI for predicted runtime must include actual runtime (i.e., sum of
  runtimes of all tasks in job)

# Multiple Processor case

## Case 1: < 50 tasks/job

## Case 2: > 50 tasks/job

## Validation
* When runtimes are exponentially distributed, compare with LEPTF
* When runtimes are NOT exponentially distributed, compare with 'truth'
generated by exhaustive search of sample space


# Conclusions and future work

## Conclusions

This is the conclusion

## Future work

This is future work to be done

### Extension to Spot instances
Currently, cost = runtime (hrs) x cost (\$/hr).
Cost is assumed to be fixed while runtime is variable.
Spot instances are much cheaper by their cost is variable.
This introduced additional level of uncertainty into the model.
Cost for Spot instances is given as time series data generated from an unknown model.
Need to model the cost effectively and pick a maximum bid price such that the job is not interrupted because the current Spot price exceeds the max bid price.
Can extend this further by using a low bid price with checkpointing and re-processing the task that was interrupted and processing all remaining tasks
Need to consider the possibility that might not get a Spot instance and will have to use an On Demand instance instead for the remaining tasks.

### Variance of runtimes & trainingset sample sizes
Currently using a fixed number of samples for each task size.
It is possible that different task sizes will have different number of training set samples.
Runtimes for task sizes with large number of training set samples will have lower variance that runtimes for sizes with fewer number of samples.
Also, the same task size can have different number of samples for different instances types.
Similarly, runtimes for a size on an instance with a large number of samples will have lower variance than runtimes for the same size on other instances with fewer number of samples.
Can choose to run task on instance type with fewer number of samples in case it turns out to faster than an instance type with more samples.
Possible use of multi-armed bandits to balance explore vs. exploit here since runtimes for current set of tasks will be added to training set for tasks from the next job.

### Move bootstrap code from R to C++
All code is currently in R and can take several minutes to run depending on the number of instances and tasks.
Move the bootstrap code to C++ and call from R via RCpp to improve runtimes.

### Skip runtime estimation for cluster sizes that are very unlikely to complete the tasks by the deadline
When trying to determine the minimum number of instances in a cluster of a certain instance type that will complete the job by the deadline, we should ignore clusters with too few instances and focus only on cluster sizes that have a reasonable chance of completing the job by the deadline.
Use the min values in the training set for each size and see if the cluster is able to complete them by the deadline.
If not, move on to the next size.


# Bibliography
